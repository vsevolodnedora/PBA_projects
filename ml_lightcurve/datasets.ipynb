{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare train/test datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec7864b2248c8090"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:36.629070462Z",
     "start_time": "2023-12-12T15:27:36.627247080Z"
    }
   },
   "id": "e060c71845ec3c51"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6480000 entries, 0 to 6479999\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   eps_e      float64\n",
      " 1   eps_b      float64\n",
      " 2   eps_t      float64\n",
      " 3   p          float64\n",
      " 4   theta_obs  float64\n",
      " 5   n_ism      float64\n",
      " 6   freq       float64\n",
      " 7   time       float64\n",
      " 8   flux       float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 494.4 MB\n",
      "None\n",
      "File loaded: /media/vsevolod/T7/work/prj_kn_afterglow/SFHoTim276_13_14_0025_150mstg_B0_HLLC/collated.csv None\n"
     ]
    }
   ],
   "source": [
    "AFGRUNDIR = \"/media/vsevolod/T7/work/prj_kn_afterglow/\"\n",
    "sim = {}; sim[\"name\"] = \"SFHoTim276_13_14_0025_150mstg_B0_HLLC\"\n",
    "collated_file_path = AFGRUNDIR + sim[\"name\"] + '/' + \"collated.csv\"\n",
    "\n",
    "assert os.path.isfile(collated_file_path), \"Collated file not found\"\n",
    "df = pd.read_csv(collated_file_path, index_col=0)\n",
    "print(f\"File loaded: {collated_file_path} {print(df.info(memory_usage='deep'))}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:40.128274672Z",
     "start_time": "2023-12-12T15:27:36.843688119Z"
    }
   },
   "id": "6c8e869ea16916fc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "target = \"flux\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:40.133974748Z",
     "start_time": "2023-12-12T15:27:40.129628107Z"
    }
   },
   "id": "546d36906b51b489"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t> Visualizing SFHoTim276_13_14_0025_150mstg_B0_HLLC Shape: (6480000, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   eps_e  eps_b  eps_t    p  theta_obs  n_ism          freq           time  \\\n0  0.001  0.001   0.01  2.2        0.0  0.001  2.400000e+09  100000.000000   \n1  0.001  0.001   0.01  2.2        0.0  0.001  2.400000e+09  106332.657164   \n\n           flux  \n0  7.278929e-11  \n1  8.460537e-11  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eps_e</th>\n      <th>eps_b</th>\n      <th>eps_t</th>\n      <th>p</th>\n      <th>theta_obs</th>\n      <th>n_ism</th>\n      <th>freq</th>\n      <th>time</th>\n      <th>flux</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>0.01</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>0.001</td>\n      <td>2.400000e+09</td>\n      <td>100000.000000</td>\n      <td>7.278929e-11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>0.01</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>0.001</td>\n      <td>2.400000e+09</td>\n      <td>106332.657164</td>\n      <td>8.460537e-11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Duplicated_rows: 0\n",
      "\t> Numeric features: 9 \n",
      "Index(['eps_e', 'eps_b', 'eps_t', 'p', 'theta_obs', 'n_ism', 'freq', 'time',\n",
      "       'flux'],\n",
      "      dtype='object')\n",
      "\t> Object features: 0 \n",
      "Index([], dtype='object')\n",
      "\t Analyzing SFHoTim276_13_14_0025_150mstg_B0_HLLC Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": "           is_unique   unique  with_nan  percent_nan           min  \\\neps_e          False        5     False          0.0  1.000000e-03   \neps_b          False        5     False          0.0  1.000000e-03   \neps_t          False        4     False          0.0  1.000000e-02   \np              False        4     False          0.0  2.200000e+00   \ntheta_obs      False        3     False          0.0  0.000000e+00   \nn_ism          False        6     False          0.0  1.000000e-03   \nfreq           False        6     False          0.0  2.400000e+09   \ntime           False      150     False          0.0  1.000000e+05   \nflux            True  6480000     False          0.0  4.115669e-13   \n\n                    max          mean    dtype  \neps_e      5.000000e-01  1.322000e-01  float64  \neps_b      5.000000e-01  1.322000e-01  float64  \neps_t      1.000000e+00  4.025000e-01  float64  \np          2.800000e+00  2.500000e+00  float64  \ntheta_obs  1.570796e+00  7.853982e-01  float64  \nn_ism      1.000000e+00  2.768333e-01  float64  \nfreq       9.300000e+10  3.123333e+10  float64  \ntime       9.404449e+08  1.052639e+08  float64  \nflux       1.015367e+02  1.489473e-01  float64  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_unique</th>\n      <th>unique</th>\n      <th>with_nan</th>\n      <th>percent_nan</th>\n      <th>min</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>dtype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>eps_e</th>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.000000e-03</td>\n      <td>5.000000e-01</td>\n      <td>1.322000e-01</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>eps_b</th>\n      <td>False</td>\n      <td>5</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.000000e-03</td>\n      <td>5.000000e-01</td>\n      <td>1.322000e-01</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>eps_t</th>\n      <td>False</td>\n      <td>4</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.000000e-02</td>\n      <td>1.000000e+00</td>\n      <td>4.025000e-01</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>p</th>\n      <td>False</td>\n      <td>4</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>2.200000e+00</td>\n      <td>2.800000e+00</td>\n      <td>2.500000e+00</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>theta_obs</th>\n      <td>False</td>\n      <td>3</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1.570796e+00</td>\n      <td>7.853982e-01</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>n_ism</th>\n      <td>False</td>\n      <td>6</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.000000e-03</td>\n      <td>1.000000e+00</td>\n      <td>2.768333e-01</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>False</td>\n      <td>6</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>2.400000e+09</td>\n      <td>9.300000e+10</td>\n      <td>3.123333e+10</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>time</th>\n      <td>False</td>\n      <td>150</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.000000e+05</td>\n      <td>9.404449e+08</td>\n      <td>1.052639e+08</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>flux</th>\n      <td>True</td>\n      <td>6480000</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>4.115669e-13</td>\n      <td>1.015367e+02</td>\n      <td>1.489473e-01</td>\n      <td>float64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _visualize_df(df:pd.DataFrame, name:str):\n",
    "    print(f\"\\t> Visualizing {name} Shape: {df.shape}\")\n",
    "\n",
    "    display(df.head(2))\n",
    "\n",
    "    print(f\"\\t Duplicated_rows: {df.duplicated().sum()}\")\n",
    "\n",
    "    # check df properties\n",
    "    def analyze_df(df : pd.DataFrame)->pd.DataFrame:\n",
    "        res = pd.DataFrame({\n",
    "            \"is_unique\": df.nunique() == len(df),\n",
    "            \"unique\": df.nunique(),\n",
    "            \"with_nan\":df.isna().any(),\n",
    "            \"percent_nan\":round((df.isnull().sum()/len(df))*100,4),\n",
    "            \"min\":df.min(),\n",
    "            \"max\":df.max(),\n",
    "            \"mean\":df.mean(),\n",
    "            \"dtype\":df.dtypes\n",
    "        })\n",
    "        return res\n",
    "    print(f\"\\t> Numeric features: {df.select_dtypes(exclude='object').shape[1]} \\n\"\n",
    "          f\"{df.select_dtypes(exclude='object').keys()}\")\n",
    "    print(f\"\\t> Object features: {df.select_dtypes(exclude='number').shape[1]} \\n\"\n",
    "          f\"{df.select_dtypes(exclude='number').keys()}\")\n",
    "    print(f\"\\t Analyzing {name} Summary:\")\n",
    "    metadata = analyze_df(df=df)\n",
    "    return metadata\n",
    "metadata = _visualize_df(df=df, name=sim[\"name\"])\n",
    "display(metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:45.069102333Z",
     "start_time": "2023-12-12T15:27:40.133140937Z"
    }
   },
   "id": "40829df753c3f4a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Select and tansform features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c8fcf2d5bd3de73"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Set target\n",
    "metadata[\"target\"] = \"flux\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:45.077301270Z",
     "start_time": "2023-12-12T15:27:45.069902642Z"
    }
   },
   "id": "7bc789908ccb6eac"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of light curves: 43200 times: 150\n"
     ]
    }
   ],
   "source": [
    "# Print total number of lightcurves\n",
    "n_curves = np.prod([metadata[\"unique\"][key] for key in df.columns if key not in [\"flux\",\"time\"]])\n",
    "n_times = metadata[\"unique\"][\"time\"]\n",
    "print(f\"total number of light curves: {n_curves} times: {n_times}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:45.077729731Z",
     "start_time": "2023-12-12T15:27:45.072821655Z"
    }
   },
   "id": "68ea15e9e6e17967"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "[[ 1  2  3  4  5 10]\n",
      " [ 1  2  3  4  5 20]\n",
      " [ 1  2  3  4  5 30]]\n"
     ]
    }
   ],
   "source": [
    "unique_times = np.array([10, 20, 30])\n",
    "physical_parameters = np.array([1,2,3,4,5])\n",
    "all_data_input = np.hstack((\n",
    "    np.repeat(physical_parameters.reshape(1, -1), len(unique_times), axis=0),\n",
    "    unique_times.reshape(-1, 1)\n",
    "))\n",
    "print(all_data_input.shape)\n",
    "print(all_data_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:45.079241321Z",
     "start_time": "2023-12-12T15:27:45.075488369Z"
    }
   },
   "id": "7c24dde49043d444"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_e        flux\n",
      "eps_b        flux\n",
      "eps_t        flux\n",
      "p            flux\n",
      "theta_obs    flux\n",
      "n_ism        flux\n",
      "freq         flux\n",
      "time         flux\n",
      "flux         flux\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(metadata[\"target\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:45.081246564Z",
     "start_time": "2023-12-12T15:27:45.079909796Z"
    }
   },
   "id": "5e3feb590dcb468b"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_96209/2536776855.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mgrouped\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupby\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"eps_e\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"eps_t\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"eps_b\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"n_ism\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"theta_obs\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"freq\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   5985\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5986\u001B[0m             \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5987\u001B[0m         ):\n\u001B[1;32m   5988\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5989\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "grouped=df.groupby([\"eps_e\",\"eps_t\",\"eps_b\",\"n_ism\",\"theta_obs\",\"freq\"])\n",
    "print(df.unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:55:46.970353028Z",
     "start_time": "2023-12-12T15:55:46.928008256Z"
    }
   },
   "id": "3e0bb411056dcca3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target name: 'flux' features_names: ['eps_e', 'eps_b', 'eps_t', 'p', 'theta_obs', 'n_ism', 'freq']\n",
      "Total number of light curves: 43200 times: 150\n",
      "f=eps_e val=0.001\n",
      "f=eps_e val=0.01\n",
      "f=eps_e val=0.05\n",
      "f=eps_e val=0.1\n",
      "f=eps_e val=0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LcCollatedDataFrameToNumpyArray(df:pd.DataFrame, metadata:pd.DataFrame,target=\"flux\",time=\"time\"):\n",
    "\n",
    "    features_names = [col for col in list(df.columns) if col not in [target,time]]\n",
    "    print(f\"Target name: '{target}' features_names: {features_names}\")\n",
    "    \n",
    "    n_curves = np.prod([metadata[\"unique\"][key] for key in df.columns if key not in [\"flux\",\"time\"]])\n",
    "    n_times = metadata[\"unique\"][\"time\"]\n",
    "    print(f\"Total number of light curves: {n_curves} times: {n_times}\")\n",
    "    \n",
    "    lcs = []#np.empty(n_curves)\n",
    "    pars = []#np.empty(n_curves)\n",
    "\n",
    "    grouped = df.groupby(features_names)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tmp = {}\n",
    "    for (i, f) in enumerate(features_names):\n",
    "        unique_vals = df[f].unique()\n",
    "        tmp[f] = unique_vals\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        for (j, val) in enumerate(df[f].unique()):\n",
    "            print(\"f={} val={}\".format(f, val))\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "LcCollatedDataFrameToNumpyArray(df, metadata)    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:45.181616839Z",
     "start_time": "2023-12-12T15:27:45.084609380Z"
    }
   },
   "id": "c1c2ebdc52c257c2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:27:46.022135496Z",
     "start_time": "2023-12-12T15:27:45.174044856Z"
    }
   },
   "id": "7e6217ac6b697405"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_train = [i_train_example, ] Y_train = [ flux[t] ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92403b40ac774397"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LightCurveDataset(Dataset):\n",
    "    def __init__(self,pars:np.ndarray, lcs:np.ndarray, times:np.ndarray):\n",
    "        self.pars = np.array(pars)\n",
    "        self.lcs = np.array(lcs)\n",
    "        assert self.pars.shape[0] == self.lcs.shape[0], \"size mismatch between lcs and pars\"\n",
    "        self.times = times\n",
    "        self.len = len(lcs)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" returns image/lc, vars(params) \"\"\"\n",
    "        return (self.lcs[index], self.pars[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lcs)\n",
    "    \n",
    "    def get_dataloader(self, batch_size=32, test_split=0.2):\n",
    "        dataset_size = len(self)\n",
    "        indices = list(range(dataset_size))\n",
    "        split = int(np.floor(test_split * dataset_size))\n",
    "        np.random.shuffle(indices)\n",
    "        train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "        # Creating PT data samplers and loaders:\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "        train_loader = DataLoader(self, batch_size=batch_size,\n",
    "                                  sampler=train_sampler, drop_last=False)\n",
    "        test_loader = DataLoader(self, batch_size=batch_size,\n",
    "                                 sampler=test_sampler, drop_last=False)\n",
    "        \n",
    "        return train_loader, test_loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3901bd960dbe089e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
